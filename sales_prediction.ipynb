{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-sQegQ8xM67",
        "outputId": "bc5fb9ec-d501-4532-ba22-8082b464509c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=d6917673d93a05a31f0815b67573490f1b7698c8b9c8f866991cde98633d85e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import when\n",
        "spark = SparkSession.builder.appName(\"Sales Prediction\").getOrCreate()\n",
        "\n",
        "data = spark.read.csv(\"/content/advertising.csv\", header=True, inferSchema=True)\n",
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCi2i0e1x3wu",
        "outputId": "bfb039e4-0011-48bc-910a-83978ac6fea6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+---------+-----+\n",
            "|   TV|Radio|Newspaper|Sales|\n",
            "+-----+-----+---------+-----+\n",
            "|230.1| 37.8|     69.2| 22.1|\n",
            "| 44.5| 39.3|     45.1| 10.4|\n",
            "| 17.2| 45.9|     69.3| 12.0|\n",
            "|151.5| 41.3|     58.5| 16.5|\n",
            "|180.8| 10.8|     58.4| 17.9|\n",
            "|  8.7| 48.9|     75.0|  7.2|\n",
            "| 57.5| 32.8|     23.5| 11.8|\n",
            "|120.2| 19.6|     11.6| 13.2|\n",
            "|  8.6|  2.1|      1.0|  4.8|\n",
            "|199.8|  2.6|     21.2| 15.6|\n",
            "| 66.1|  5.8|     24.2| 12.6|\n",
            "|214.7| 24.0|      4.0| 17.4|\n",
            "| 23.8| 35.1|     65.9|  9.2|\n",
            "| 97.5|  7.6|      7.2| 13.7|\n",
            "|204.1| 32.9|     46.0| 19.0|\n",
            "|195.4| 47.7|     52.9| 22.4|\n",
            "| 67.8| 36.6|    114.0| 12.5|\n",
            "|281.4| 39.6|     55.8| 24.4|\n",
            "| 69.2| 20.5|     18.3| 11.3|\n",
            "|147.3| 23.9|     19.1| 14.6|\n",
            "+-----+-----+---------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvYfW-Ik1LWq",
        "outputId": "4e785d32-366e-4a04-e214-4ce96a957b7e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uxdvxdE1LZh",
        "outputId": "94f0963f-0502-43f9-9fd7-43aa547877c0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- TV: double (nullable = true)\n",
            " |-- Radio: double (nullable = true)\n",
            " |-- Newspaper: double (nullable = true)\n",
            " |-- Sales: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.na.drop().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZRsnE5n1LcA",
        "outputId": "0cc95f57-1811-443a-c278-ecaf59d0fd80"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+---------+-----+\n",
            "|   TV|Radio|Newspaper|Sales|\n",
            "+-----+-----+---------+-----+\n",
            "|230.1| 37.8|     69.2| 22.1|\n",
            "| 44.5| 39.3|     45.1| 10.4|\n",
            "| 17.2| 45.9|     69.3| 12.0|\n",
            "|151.5| 41.3|     58.5| 16.5|\n",
            "|180.8| 10.8|     58.4| 17.9|\n",
            "|  8.7| 48.9|     75.0|  7.2|\n",
            "| 57.5| 32.8|     23.5| 11.8|\n",
            "|120.2| 19.6|     11.6| 13.2|\n",
            "|  8.6|  2.1|      1.0|  4.8|\n",
            "|199.8|  2.6|     21.2| 15.6|\n",
            "| 66.1|  5.8|     24.2| 12.6|\n",
            "|214.7| 24.0|      4.0| 17.4|\n",
            "| 23.8| 35.1|     65.9|  9.2|\n",
            "| 97.5|  7.6|      7.2| 13.7|\n",
            "|204.1| 32.9|     46.0| 19.0|\n",
            "|195.4| 47.7|     52.9| 22.4|\n",
            "| 67.8| 36.6|    114.0| 12.5|\n",
            "|281.4| 39.6|     55.8| 24.4|\n",
            "| 69.2| 20.5|     18.3| 11.3|\n",
            "|147.3| 23.9|     19.1| 14.6|\n",
            "+-----+-----+---------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.withColumn(\"label\", when(data[\"Sales\"] < 10, 0)\n",
        "                       .when((data[\"Sales\"] >= 10) & (data[\"Sales\"] <= 20), 1)\n",
        "                       .otherwise(2))"
      ],
      "metadata": {
        "id": "GjpMUrABy7vS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler = VectorAssembler(inputCols=[\"TV\", \"Radio\", \"Newspaper\"], outputCol=\"features\")\n",
        "data = assembler.transform(data)"
      ],
      "metadata": {
        "id": "FEkwDoQvyFfa"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "id": "SdAxivCiyKmK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
        "lr_model = lr.fit(train_data)\n",
        "lr_predictions = lr_model.transform(test_data)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "lr_accuracy = evaluator.setMetricName(\"accuracy\").evaluate(lr_predictions)\n",
        "lr_f1 = evaluator.setMetricName(\"f1\").evaluate(lr_predictions)\n",
        "\n",
        "print(f\"Logistic Regression Accuracy: {lr_accuracy*100:.2f}%\")\n",
        "print(f\"Logistic Regression F1 Score: {lr_f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knmfnlJYyY8e",
        "outputId": "db9e46ce-271d-4315-9133-b89ab9e82a8c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 85.11%\n",
            "Logistic Regression F1 Score: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
        "rf_model = rf.fit(train_data)\n",
        "rf_predictions = rf_model.transform(test_data)\n",
        "\n",
        "rf_accuracy = evaluator.setMetricName(\"accuracy\").evaluate(rf_predictions)\n",
        "rf_f1 = evaluator.setMetricName(\"f1\").evaluate(rf_predictions)\n",
        "\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy*100:.2f}%\")\n",
        "print(f\"Random Forest F1 Score: {rf_f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8JtMGiqyc2X",
        "outputId": "248de55c-5bc8-4826-fba9-1614d47c94e8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 89.36%\n",
            "Random Forest F1 Score: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "df = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
        "df_model = df.fit(train_data)\n",
        "df_predictions = df_model.transform(test_data)\n",
        "\n",
        "df_accuracy = evaluator.setMetricName(\"accuracy\").evaluate(df_predictions)\n",
        "df_f1 = evaluator.setMetricName(\"f1\").evaluate(df_predictions)\n",
        "\n",
        "print(f\"Random Forest Accuracy: {df_accuracy*100:.2f}%\")\n",
        "print(f\"Random Forest F1 Score: {df_f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ64UHBvT5r6",
        "outputId": "b8997b4e-8dfe-456e-baec-61700be19242"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 89.36%\n",
            "Random Forest F1 Score: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "nr = NaiveBayes(featuresCol=\"features\", labelCol=\"label\")\n",
        "nr_model = nr.fit(train_data)\n",
        "\n",
        "nr_predictions = nr_model.transform(test_data)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "nr_accuracy = evaluator.setMetricName(\"accuracy\").evaluate(nr_predictions)\n",
        "nr_f1 = evaluator.setMetricName(\"f1\").evaluate(nr_predictions)\n",
        "\n",
        "print(f\"Naive Bayes Accuracy: {nr_accuracy*100:.2f}%\")\n",
        "print(f\"Naive Bayes F1 Score: {nr_f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQAjFyzsTXGM",
        "outputId": "214f0617-4048-4ed9-abb9-1e9ec0e8f870"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 51.06%\n",
            "Naive Bayes F1 Score: 0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "aZUpt9A9z8KR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nYzS9nk31ju7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}